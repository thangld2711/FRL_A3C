## Problem Statement

Tackling the problem of selecting the correct exploit given a certain state is a difficult task.
The challenge is that the action space is big **800+ exploits** exploits while the testing data and input space are limited.


## The approach

Taking actions randomly will yield almost no positive results - as stated above that the action space is big -. So, in each iteration, Shennina picks a number of the "likely to succeed" exploits and tries it against the target. If it works. It'll be rewarded, and the network weights will be updated to increase the probabilities to pick this action in the action in future - given the same state -. And the network will do the opposite in case it failed.
So as the network learns more, the weights are updated toward the more successful exploits. But, given that the action space is big, and the number of training data is small compared to it. It's not assured in the testing phase that the exploit picked will be the suitable one. We've solved this by selecting the top N exploits given a certain state.


#### Results

Running the project against a target "metasploitable2" with this configuration:
1. N = 3: Top 3 exploits per service.
2. Workers = 1. One worker per target.

has yielded the following results:
* Returned shells: 5 out of 8.
* Accuracy: 62%

Running the project against a target "metasploitable2" with this configuration:
1. N = 4: Top 4 exploits per service.
2. Workers = 1. One worker per target.

has yielded the following results:
* Returned shells: 6 out of 8.
* Accuracy: 75%

Running the project against a target "metasploitable2" with this configuration:
1. N = 5: Top 4 exploits per service.
2. Workers = 1. One worker per target.

has yielded the following results:
* Returned shells: 8 out of 8.
* Accuracy: 100%


![Graph of N vs Accuracy](/docs/images/n-vs-accuracy.png)
- In some cases, we have noticed that the AI engine would suggest irrelevant exploits given a certain service name. So, in order to avoid getting false results, we have introduced a rectifying function to conditionally add exploits to the execution list if the exploits are relevant to the current state.

##### Conclusion

- Since the action space is big, unless the training data points number exceeds the number of action space, reaching an exact match in a single try can be difficult.
- We have tried to solve this challenge using the N number of top recommended exploits. Which yielded the above results.
- We also noticed that increasing N will increase the execution time. We've also solved this issue by returning from the function as soon as we get a positive result.
